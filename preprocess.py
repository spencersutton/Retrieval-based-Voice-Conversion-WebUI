import logging
import sys
import threading
import warnings
from pathlib import Path
from subprocess import Popen
from time import sleep

import gradio as gr
import numpy as np
import torch
from dotenv import load_dotenv
from fairseq.modules.grad_multiply import GradMultiply

from configs.config import Config
from i18n.i18n import I18nAuto

now_dir = Path.cwd()
sys.path.append(str(now_dir))
load_dotenv()

logging.getLogger("numba").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)

(now_dir / "logs").mkdir(parents=True, exist_ok=True)
warnings.filterwarnings("ignore")
torch.manual_seed(114514)


config = Config()


if config.dml:

    def forward_dml(ctx, x, scale):
        ctx.scale = scale
        res = x.clone().detach()
        return res

    GradMultiply.forward = forward_dml

i18n = I18nAuto()
logger.info(i18n)


_sr_dict = {
    "32k": 32000,
    "40k": 40000,
    "48k": 48000,
}


def _if_done(done, p):
    while 1:
        if p.poll() is None:
            sleep(0.5)
        else:
            break
    done[0] = True


def _preprocess_dataset(
    training_file: gr.FileData, exp_dir: str, sample_rate_str: str, n_p: int
):
    training_dir = Path(str(training_file)).parent
    sr = _sr_dict[sample_rate_str]  # Sample rate

    log_dir = now_dir / "logs" / exp_dir
    log_dir.mkdir(parents=True, exist_ok=True)
    log_file = log_dir / "preprocess.log"
    log_file.touch()

    cmd = f'"{config.python_cmd}" infer/modules/train/preprocess.py "{training_dir}" {sr} {n_p} "{log_dir}" {config.noparallel} {config.preprocess_per:.1f}'
    logger.info("Execute: %s", cmd)
    p = Popen(cmd, shell=True)
    done = [False]
    threading.Thread(target=_if_done, args=(done, p)).start()
    while True:
        yield log_file.read_text()
        sleep(1)
        if done[0]:
            break
    log = log_file.read_text()
    logger.info(log)
    yield log


with gr.Blocks(title="RVC WebUI") as app:
    gr.Markdown("## RVC WebUI")
    gr.Markdown(
        value=i18n(
            "This software is open source under the MIT license. The author has no control over the software. Users and those who distribute sounds generated by the software are solely responsible. <br>If you do not accept these terms, you may not use or reference any code or files in this package. See <b>LICENSE</b> in the root directory for details."
        )
    )
    with gr.Tabs():
        with gr.TabItem(i18n("Training")):
            gr.Markdown(
                value=i18n(
                    "Step 1: Fill in the experiment configuration. Experiment data is stored in the logs directory, each experiment has its own folder, you need to manually enter the experiment name and path, which contains the experiment configuration, logs, and trained model files."
                )
            )
            with gr.Row():
                gr_experiment_dir = gr.Textbox(
                    label=i18n("Enter experiment name"), value="mi-test"
                )
                gr_sample_rate = gr.Radio(
                    label=i18n("Target sample rate"),
                    choices=["40k", "48k"],
                    value="40k",
                    interactive=True,
                )
                if_f0_3 = gr.Radio(
                    label=i18n(
                        "Does the model use pitch guidance? (Required for singing, optional for speech)"
                    ),
                    choices=[True, False],
                    value=True,
                    interactive=True,
                )
                gr_version = gr.Radio(
                    label=i18n("Version"),
                    choices=["v1", "v2"],
                    value="v2",
                    interactive=True,
                    visible=True,
                )
                np7 = gr.Slider(
                    minimum=0,
                    maximum=config.n_cpu,
                    step=1,
                    label=i18n(
                        "Number of CPU processes for pitch extraction and data processing"
                    ),
                    value=int(np.ceil(config.n_cpu / 1.5)),
                    interactive=True,
                )
            with gr.Group():  # 暂时单人的, 后面支持最多4人的#数据处理
                gr.Markdown(
                    value=i18n(
                        "Step 2a: Automatically traverse all decodable files in the training folder and perform slicing and normalization, generating 2 wav folders in the experiment directory; currently only supports single-person training."
                    )
                )
                with gr.Row():
                    trainset_dir4 = gr.File(
                        label=i18n("Upload training file"),
                        file_count="single",
                    )
                    spk_id5 = gr.Slider(
                        minimum=0,
                        maximum=4,
                        step=1,
                        label=i18n("Please specify speaker id"),
                        value=0,
                        interactive=True,
                    )
                    but1 = gr.Button(i18n("Process data"), variant="primary")
                    info1 = gr.Textbox(label=i18n("Output information"), value="")
                    but1.click(
                        _preprocess_dataset,
                        [trainset_dir4, gr_experiment_dir, gr_sample_rate, np7],
                        [info1],
                        api_name="train_preprocess",
                    )

    if config.iscolab:
        app.queue(max_size=1022).launch(share=True)
    else:
        app.queue(max_size=1022).launch(
            server_name="0.0.0.0",
            inbrowser=not config.noautoopen,
            server_port=config.listen_port,
            quiet=True,
        )
